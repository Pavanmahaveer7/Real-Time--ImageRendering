{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubnGE0v05Eg7",
        "outputId": "631559fc-9dea-4993-a9c6-51a88003e483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 29 19:55:03 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ArpSg_65HC8",
        "outputId": "508c10fe-d3ed-4934-ae79-9d816632b589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void helloCUDA()\n",
        "{\n",
        "    printf(\"Hello CUDA from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    helloCUDA<<<1, 1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82BC3d8N5Mip",
        "outputId": "0a8a6e54-0eb9-461c-cb10-97e6a6c5a5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Cell magic `%%cu` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_code.cu\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void helloCUDA()\n",
        "{\n",
        "    printf(\"Hello CUDA from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    helloCUDA<<<1, 1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncOO6YiC5SSd",
        "outputId": "6c923231-06c0-4c64-f48f-905d686cdb9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_code.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o cuda_code_cuda cuda_code.cu\n",
        "!./cuda_code_cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG_cxWUd5aog",
        "outputId": "4b9e50e6-51a9-4f7d-9f78-64c4b2ac46f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello CUDA from GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_code_1.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "int main() {\n",
        "    const int batch_size = 128;\n",
        "    const int input_size = 256;\n",
        "    const int output_size = 10;  // 10 output classes for MNIST\n",
        "\n",
        "    // Allocate host memory for input and weights\n",
        "    std::vector<float> input(batch_size * input_size);\n",
        "    std::vector<float> weights(input_size * output_size);\n",
        "\n",
        "    // Initialize input and weights with random values\n",
        "    for (int i = 0; i < batch_size * input_size; ++i) {\n",
        "        input[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "    for (int i = 0; i < input_size * output_size; ++i) {\n",
        "        weights[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_input, *d_weights, *d_output;\n",
        "    cudaMalloc(&d_input, batch_size * input_size * sizeof(float));\n",
        "    cudaMalloc(&d_weights, input_size * output_size * sizeof(float));\n",
        "    cudaMalloc(&d_output, batch_size * output_size * sizeof(float));\n",
        "\n",
        "    // Copy input and weights to device\n",
        "    cudaMemcpy(d_input, input.data(), batch_size * input_size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_weights, weights.data(), input_size * output_size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Create cuBLAS handle\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    // Perform vector multiplication\n",
        "    float alpha = 1.0f, beta = 0.0f;\n",
        "    cublasSgemv(handle, CUBLAS_OP_N, output_size, input_size, &alpha,\n",
        "                d_weights, output_size, d_input, 1, &beta, d_output, 1);\n",
        "\n",
        "    // Destroy cuBLAS handle\n",
        "    cublasDestroy(handle);\n",
        "\n",
        "    // Copy output back to host\n",
        "    std::vector<float> output(batch_size * output_size);\n",
        "    cudaMemcpy(output.data(), d_output, batch_size * output_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_weights);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    // Print a sample output\n",
        "    std::cout << \"Sample output:\" << std::endl;\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        std::cout << output[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0q5dexbbm3y",
        "outputId": "db9d6190-acf6-4fea-a422-60c2c80f821a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_code_1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o cuda_code_1_cuda cuda_code_1.cu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1saqARzcEko",
        "outputId": "65a109d3-d255-4874-bd0e-b7b2b5c61013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/ld: /tmp/tmpxft_000008d5_00000000-11_cuda_code_1.o: in function `main':\n",
            "tmpxft_000008d5_00000000-6_cuda_code_1.cudafe1.cpp:(.text+0x20a): undefined reference to `cublasCreate_v2'\n",
            "/usr/bin/ld: tmpxft_000008d5_00000000-6_cuda_code_1.cudafe1.cpp:(.text+0x270): undefined reference to `cublasSgemv_v2'\n",
            "/usr/bin/ld: tmpxft_000008d5_00000000-6_cuda_code_1.cudafe1.cpp:(.text+0x280): undefined reference to `cublasDestroy_v2'\n",
            "collect2: error: ld returned 1 exit status\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use GPU 0"
      ],
      "metadata": {
        "id": "-VMB6wTVdXPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOLeImOwd1yE",
        "outputId": "98075213-0e73-4969-9242-1992bd6ee44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 29 20:06:35 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               8W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ldconfig /usr/local/cuda-11.8/targets/x86_64-linux/lib/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mlutg6fodXSn",
        "outputId": "38fa4d02-bc85-410d-a7f5-7105b7d02775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ldconfig /usr/local/cuda/targets/x86_64-linux/lib/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7f9xt86d76G",
        "outputId": "75313d0a-74fe-4ddc-d193-089a81ee2e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --compiler-options '-lcublas -lcudart -lcudnn -lcurand' --include-paths '/usr/local/cuda/targets/x86_64-linux/include/' --libraries '/usr/local/cuda/targets/x86_64-linux/lib/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8Od8P83d79S",
        "outputId": "1af6f051-00ee-4f07-9858-28d0162e3505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Cell magic `%%cuda` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_code_1.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "int main() {\n",
        "    const int batch_size = 128;\n",
        "    const int input_size = 256;\n",
        "    const int output_size = 10;  // 10 output classes for MNIST\n",
        "\n",
        "    // Allocate host memory for input and weights\n",
        "    std::vector<float> input(batch_size * input_size);\n",
        "    std::vector<float> weights(input_size * output_size);\n",
        "\n",
        "    // Initialize input and weights with random values\n",
        "    for (int i = 0; i < batch_size * input_size; ++i) {\n",
        "        input[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "    for (int i = 0; i < input_size * output_size; ++i) {\n",
        "        weights[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_input, *d_weights, *d_output;\n",
        "    cudaMalloc(&d_input, batch_size * input_size * sizeof(float));\n",
        "    cudaMalloc(&d_weights, input_size * output_size * sizeof(float));\n",
        "    cudaMalloc(&d_output, batch_size * output_size * sizeof(float));\n",
        "\n",
        "    // Copy input and weights to device\n",
        "    cudaMemcpy(d_input, input.data(), batch_size * input_size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_weights, weights.data(), input_size * output_size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Create cuBLAS handle\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    // Perform vector multiplication\n",
        "    float alpha = 1.0f, beta = 0.0f;\n",
        "    cublasSgemv(handle, CUBLAS_OP_N, output_size, input_size, &alpha,\n",
        "                d_weights, output_size, d_input, 1, &beta, d_output, 1);\n",
        "\n",
        "    // Destroy cuBLAS handle\n",
        "    cublasDestroy(handle);\n",
        "\n",
        "    // Copy output back to host\n",
        "    std::vector<float> output(batch_size * output_size);\n",
        "    cudaMemcpy(output.data(), d_output, batch_size * output_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_weights);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    // Print a sample output\n",
        "    std::cout << \"Sample output:\" << std::endl;\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        std::cout << output[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhPEi-bHeUd9",
        "outputId": "6c0dccd5-5db3-4af8-8610-22275c53b4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_code_1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o cuda_executable cuda_code_1.cu -lcublas\n"
      ],
      "metadata": {
        "id": "1NgSe85Zd7_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./cuda_executable\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAk0Yuzfd8Cf",
        "outputId": "befde94b-de70-42b8-85f1-fb2508450d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample output:\n",
            "66.7555 68.8272 68.0738 61.9798 67.4468 64.2662 68.7616 64.612 60.7305 67.7168 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "# Compile CUDA code\n",
        "os.system('nvcc -o cuda_executable cuda_code_1.cu')\n",
        "\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute compiled CUDA code\n",
        "os.system('./cuda_executable')\n",
        "\n",
        "# Record end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate execution time\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time:\", execution_time, \"seconds\")\n",
        "\n",
        "# Calculate memory usage\n",
        "process = subprocess.Popen(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
        "                           stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "stdout, _ = process.communicate()\n",
        "memory_used = sum(int(x) for x in stdout.strip().split(b'\\n'))\n",
        "print(\"Memory used:\", memory_used, \"MiB\")\n"
      ],
      "metadata": {
        "id": "u_VLBGhkn4s3",
        "outputId": "6a7adc70-2ba0-4180-ded4-679495e11f70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.001447916030883789 seconds\n",
            "Memory used: 0 MiB\n"
          ]
        }
      ]
    }
  ]
}